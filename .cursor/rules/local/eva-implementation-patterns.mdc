---
description: Eva implementation patterns — coding conventions that have crystallized during M1–M5 implementation. Covers AppEnv/AppM, LLMClient injection, WebSocket broadcast lifecycle, retry/dispatch, frontend store, test setup, and credential encryption.
globs: ["backend/**/*.hs", "frontend/src/**/*.ts", "frontend/src/**/*.tsx"]
---

# Eva Implementation Patterns

Practical conventions from M1–M4 (Foundation → Agent Runtime). Read
alongside `eva-architecture.mdc` (design intent) and `eva-concepts.mdc`
(domain vocabulary).

## AppEnv / AppM

`AppM = ReaderT AppEnv IO`. All backend handlers live in `AppM`.

```haskell
-- Eva.App
type DispatchFn =
  RunId -> Node -> Map PortName Message -> ResourceBindings -> AppM Message

data AppEnv = AppEnv
  { envConfig     :: AppConfig
  , envDbPool     :: ConnectionPool
  , envLogger     :: LogEntry -> IO ()
  , envDispatch   :: DispatchFn          -- injectable; tests swap this
  , envLLMClient  :: LLMClient           -- injectable; tests use dummyLLMClient
  , envBroadcasts :: TVar (Map RunId (TChan Value))
  }
```

`makeAppEnv` takes `AppConfig` + a `DispatchFn`, creates the SQLite pool,
runs auto-migration, and wires up the LLM client from `configLlmApiKey`.
Pass `Eva.Engine.Dispatch.execute` in production; inject a stub in tests.

## LLMClient — Record of Functions

`LLMClient` is a record-of-functions (not a typeclass) to avoid
type-parameter complexity and allow easy injection.

```haskell
data LLMClient = LLMClient
  { clientCall   :: LLMRequest -> IO (Either LLMError LLMResponse)
  , clientStream :: LLMRequest -> (Text -> IO ()) -> IO (Either LLMError LLMResponse)
  }
```

- **Production:** `mkOpenAIClient apiKey` — creates a TLS manager, returns
  a client backed by the OpenAI chat completions endpoint.
- **Tests/unconfigured:** `dummyLLMClient` — every call returns
  `Left (LLMAuthError "no LLM client configured")`.
- **Streaming:** `clientStream` fires the `onToken :: Text -> IO ()` callback
  for each SSE delta token, then returns the complete `LLMResponse` with
  total token usage.

### SSE streaming internals (LLM.hs)

- Uses `withResponse` (streaming body) rather than `httpLbs`.
- Maintains a `leftoverRef :: IORef ByteString` for line fragments that span
  chunks — splits on `\n`, processes complete lines, keeps the remainder.
- Requests `stream_options: { include_usage: true }` so the final SSE chunk
  carries `TokenUsage`; intermediate chunks may have `null` usage.
- `parseSseLine` returns `Nothing` for blank lines, non-`data:` lines, and
  `[DONE]`. Both functions are exported for unit testing.

### LLM error taxonomy

```haskell
data LLMError
  = LLMAuthError Text       -- 401 / 403
  | LLMRateLimitError Text  -- 429
  | LLMApiError Int Text    -- other HTTP errors
  | LLMTimeoutError
  | LLMParseError Text
```

## WebSocket Broadcast — Channel Lifecycle

Each active run gets a `TChan Value` stored in `envBroadcasts`.

```
startRun:        registerRun rid channel   -- before walker starts
                                            -- so WS clients can subscribe immediately
walker/handlers: broadcastEvent rid event  -- write to channel
finishRun:       unregisterRun rid         -- remove from registry after terminal state
```

WebSocket clients call `dupTChan` to get their own read position (fanout).
`forwardEvents` reads from the dup'd channel and closes cleanly when it sees
a terminal `run_state` event (completed / failed / canceled).

`broadcastEvent` is a no-op if the run isn't in the registry (already
finished or never started) — safe to call unconditionally.

## RunContext (StateMachine.hs)

Created by `newRunContext` in `startRun`. Fields used throughout the engine:

```haskell
data RunContext = RunContext
  { rcRun              :: TVar Run
  , rcRunId            :: RunId
  , rcMailboxes        :: Map (NodeId, PortName) (TMVar Message)
  , rcSteps            :: TVar (Map NodeId (TVar Step))
  , rcDispatched       :: TVar (Set NodeId)
  , rcAllDone          :: TVar Bool
  , rcHasUnhandledError :: TVar Bool
  , rcBroadcast        :: TChan Value
  }
```

- `rcMailboxes`: one `TMVar` per required data-input port. Resource ports
  get no mailbox and do not gate readiness.
- `rcDispatched`: nodes whose step has been forked (prevents double-dispatch).
- `rcAllDone`: signaled by `checkAndSignalDone` when all terminal nodes
  reach a terminal step state; unblocks `waitForRun`.
- `rcHasUnhandledError`: set by `markUnhandledError` when a node fails with
  no wired error port; causes `finishRun` to use `RunFailed`.

## Retry / Dispatch

`dispatchWithRetry` wraps any `DispatchFn` call with:
- Optional `System.Timeout.timeout` (microseconds = `retryTimeoutMs * 1000`).
- Retry loop: up to `retryMaxAttempts` additional attempts.
- Each failed attempt logs a `warn` entry to `log_entries` + broadcasts a
  `log_entry` WS event + increments `stepRetryCount` in DB + in-memory TVar.
- Backoff: `BackoffFixed ms` (constant) or `BackoffExponential baseMs capMs`
  (`baseMs * 2^n` ms, capped).

`withRetry :: RetryPolicy -> IO a -> IO (Either SomeException a)` is exported
for standalone testing (no logging/DB).

### NodeStepFailure exception

Thrown by `executeNodeStep` when dispatch fails and the node has no wired
`"error"` output edge. Caught by the graph walker, which then calls
`skipDescendants` and sets `rcHasUnhandledError`.

If a wired error edge exists, dispatch failure instead produces an
`"error"` `Message` that propagates downstream — step state = `Failed`,
but Run continues.

## Agent Handler Pattern

`handleAgent` is called with pre-resolved `ResourceBindings` (populated by
`resolveResourceBindings` in the Runner before dispatch):

1. Extract `"instruction"` data input from mailbox map.
2. Build context section from `rbKnowledge` (M4: inline text only; M5: file/URL).
3. Assemble `[ChatMessage "system" systemPrompt, ChatMessage "user" (instruction <> contextSection)]`.
4. Call `clientStream` with `onToken` that broadcasts `llm_token` WS events.
5. Wrap response in `Message "agent_output" (toJSON content) meta`.

Tool use (`rbConnectors`) is stubbed in M4 — real loop is EVA-33.

## Frontend: Canvas Store

`useCanvasStore` (Zustand) owns all in-editor graph state:

- `isDirty` — set on any node/edge change; cleared by `markClean()` after
  successful save.
- `buildGraph() → Graph` — converts react-flow `Node<EvaNodeData>[]` +
  `Edge[]` back to the API `Graph` shape for `PUT /api/programs/:id/graph`.
- `loadGraph(graph, programId)` — replaces store state from a server `Graph`.
- Edge `type` field maps directly to `PortCategory` (`"data"` | `"resource"`).

`EvaNodeData = { label: string; nodeType: NodeType }` — the data bag on
every react-flow node. `nodeType` is the full discriminated union variant
including config.

### Undo/redo (EVA-41)

`past` / `future` arrays hold `{ nodes, edges }` snapshots (capped at 50).
`snapshot()` must be called **before** any mutating operation. Call sites:

- `addNode`, `addEdge` — call `get().snapshot()` before `set()`
- `applyNodeChanges`, `applyEdgeChanges` — snapshot only when a `remove`
  change is present (skip position/selection changes to avoid log spam)
- `CanvasContainer.onNodeDragStart` — snapshot before drag begins (captures
  position before the drag, not after each frame)

`undo()` / `redo()` swap current state with the top of `past` / `future`.
Both set `isDirty: true` so the save dot reappears.

### Auto-layout (EVA-41)

`frontend/src/lib/autoLayout.ts` — pure function `applyDagreLayout(nodes, edges) → Node[]`
using `@dagrejs/dagre` with `rankdir: 'LR', nodesep: 60, ranksep: 100`.

`setLayoutedNodes(nodes)` in the store replaces nodes and sets `triggerFitView: true`.
`CanvasInner` watches `triggerFitView` and calls `fitView({ padding: 0.3 })` via
`useReactFlow()`, then resets the flag. This pattern is needed because `fitView` is
an imperative API only available inside `ReactFlowProvider`.

### Global keyboard shortcuts

Keyboard shortcuts live in `Toolbar.tsx` via a `useEffect` attaching to
`window.addEventListener('keydown', ...)`. All shortcuts check `e.metaKey || e.ctrlKey`.
Toolbar has access to all store actions and mutation refs needed, so no separate
hook is needed. Pattern: read store values directly in the effect dependency array.

## Frontend: Query Key Factory

```typescript
export const programKeys = {
  all: ['programs'] as const,
  detail: (id: string) => ['programs', id] as const,
}
```

All mutations invalidate via these keys. `useSaveGraph` invalidates
`detail(programId)`. `useGraphInvalidation` provides an `invalidateGraph()`
callback for WS events (EVA-27 hook point).

## Haskell Test Setup Boilerplate

Tests in `Eva.Engine.Handlers.*Spec` and `Eva.Engine.RunnerSpec` share this
setup pattern:

```haskell
-- In-memory SQLite pool (isolated per test file):
pool <- runNoLoggingT $ createSqlitePool ":memory:" 1
runMigrations pool

-- Minimal AppEnv for handler tests (no real dispatch needed):
broadcasts <- newTVarIO Map.empty
let env = AppEnv
      { envConfig    = AppConfig { configDbPath = ":memory:", configLlmApiKey = Nothing
                                 , configPort = 8080, configLogLevel = LogError }
      , envDbPool    = pool
      , envLogger    = \_ -> pure ()
      , envDispatch  = error "dispatch not needed in handler tests"
      , envLLMClient = mockLLMClient  -- see below
      , envBroadcasts = broadcasts
      }
```

**Mock LLM client with captured tokens:**

```haskell
tokensRef <- newIORef ([] :: [Text])
let mockClient = LLMClient
      { clientCall   = \_ -> pure (Right (LLMResponse "mock output" (TokenUsage 1 1 2)))
      , clientStream = \_ onToken -> do
          onToken "hello "; onToken "world"
          modifyIORef' tokensRef ("hello " :)
          modifyIORef' tokensRef ("world" :)
          pure (Right (LLMResponse "hello world" (TokenUsage 1 2 3)))
      }
```

Handlers are invoked **directly** (bypassing the graph walker):

```haskell
result <- runAppM env $ handleAgent testRunId node inputs bindings
```

Runner tests that need the full walker use `startRun`/`waitForRun` with
an injectable dispatch that controls success/failure per node.

## Credential Encryption (EVA-32)

AES-256-GCM via `crypton`. Wire format: `[12-byte IV][16-byte auth tag][ciphertext]`
stored in `credentials.encrypted_data` (SQLite BLOB).

```haskell
-- Eva.Crypto
deriveKey :: ByteString -> ByteString        -- SHA-256(key_material) → 32 bytes
encrypt   :: ByteString -> ByteString -> IO ByteString   -- key, plaintext
decrypt   :: ByteString -> ByteString -> Either String ByteString  -- key, blob
```

**Key derivation:** `EVA_CREDENTIAL_KEY` env var → `TE.encodeUtf8` → `Crypto.deriveKey`
→ stored in `AppEnv.envCredentialKey :: ByteString`. Required at startup.

**AppEnv fields (EVA-32 additions):**
```haskell
AppEnv { ...
  , envCredentialKey :: ByteString  -- 32-byte AES key
  }
AppConfig { ...
  , configCredentialKey :: Text     -- raw EVA_CREDENTIAL_KEY value
  }
```

**Test harness pattern:** All test files that construct `AppConfig`/`AppEnv` must include:
```haskell
-- in AppConfig:
, configCredentialKey = "test-key"
-- in AppEnv:
, envCredentialKey = Crypto.deriveKey "test-key"
-- import:
import qualified Eva.Crypto as Crypto
```

**JSON naming:** `Credential` uses `dropPrefix "credential"` so `credentialType` serializes
as `"type"`. `CreateCredentialReq` also uses `"type"` (not `"credType"`) for consistency.
The secret field never appears in responses — only `id`, `name`, `system`, `type`, `createdAt`.

## ConnectorRunner — Record of Functions (EVA-30)

`ConnectorRunner` is a record-of-functions (parallel to `LLMClient`) defined in
`Eva.Integration.Types`. It uses `IO` (not `AppM`) to keep `Integration.Types` free of
the `AppM` dependency. **`Core.Types` re-exports `module Eva.Integration.Types`** so all
connector types are available everywhere that imports `Core.Types`.

```haskell
data ConnectorRunner = ConnectorRunner
  { connectorAvailableActions :: IO [ActionSpec]
  , connectorExecuteAction    :: ActionName -> Value -> IO (Either ConnectorError Value)
  }
```

**Resolution flow:** `Runner.resolveResourceBindings` (now `AppM`) calls
`Engine.Handlers.Connector.resolveConnectorRunner` for each `ConnectorConfig` in
resource edges. Runners are stored in `ResourceBindings.rbConnectorRunners :: [ConnectorRunner]`
alongside the raw configs in `rbConnectors`.

**Credential lookup:** `Persistence.Queries.getDecryptedCredential :: CredentialId -> AppM (Either String ByteString)` fetches and decrypts the credential row using `envCredentialKey`.

**Error hierarchy:**
```haskell
data ConnectorError
  = ConnectorMissingCredential Text  -- no credentialId set
  | ConnectorInvalidCredential Text  -- credential not found or decrypt failed
  | ConnectorUnsupported Text         -- system type not yet implemented
  | ConnectorApiError Text            -- runtime API error
```

**Adding a new connector:** implement `mkXxxRunner :: ByteString -> ConnectorConfig -> ConnectorRunner`
in `Integration/Xxx.hs`, then add the `SystemXxx` case in `Engine.Handlers.Connector.mkRunner`.

**Circular dependency note:** `Integration.Types` has NO Eva-internal imports (it uses a local
`dropPrefixOpts` copy instead of importing `dropPrefix` from `Core.Types`). This is intentional
— `Core.Types` imports `Integration.Types`, so the dependency goes one way only.

**Test pattern for ConnectorSpec:** use `withTestEnv` (same shape as AgentSpec), call
`resolveConnectorRunner cfg` directly, insert test credentials with `insertCredential`.
`ConnectorRunner` has no `Show` instance (functions can't be shown) — use
`connectorErrorText err` for failure messages instead of `show other`.
